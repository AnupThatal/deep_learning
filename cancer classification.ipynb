{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "benign_0__mal_1            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius               -0.730029\n",
       "mean texture              -0.415185\n",
       "mean perimeter            -0.742636\n",
       "mean area                 -0.708984\n",
       "mean smoothness           -0.358560\n",
       "mean compactness          -0.596534\n",
       "mean concavity            -0.696360\n",
       "mean concave points       -0.776614\n",
       "mean symmetry             -0.330499\n",
       "mean fractal dimension     0.012838\n",
       "radius error              -0.567134\n",
       "texture error              0.008303\n",
       "perimeter error           -0.556141\n",
       "area error                -0.548236\n",
       "smoothness error           0.067016\n",
       "compactness error         -0.292999\n",
       "concavity error           -0.253730\n",
       "concave points error      -0.408042\n",
       "symmetry error             0.006522\n",
       "fractal dimension error   -0.077972\n",
       "worst radius              -0.776454\n",
       "worst texture             -0.456903\n",
       "worst perimeter           -0.782914\n",
       "worst area                -0.733825\n",
       "worst smoothness          -0.421465\n",
       "worst compactness         -0.590998\n",
       "worst concavity           -0.659610\n",
       "worst concave points      -0.793566\n",
       "worst symmetry            -0.416294\n",
       "worst fractal dimension   -0.323872\n",
       "benign_0__mal_1            1.000000\n",
       "Name: benign_0__mal_1, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['benign_0__mal_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4eccca6a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['benign_0__mal_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension  benign_0__mal_1  \n",
       "count               569.000000       569.000000  \n",
       "mean                  0.083946         0.627417  \n",
       "std                   0.018061         0.483918  \n",
       "min                   0.055040         0.000000  \n",
       "25%                   0.071460         0.000000  \n",
       "50%                   0.080040         1.000000  \n",
       "75%                   0.092080         1.000000  \n",
       "max                   0.207500         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  benign_0__mal_1          569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('benign_0__mal_1',axis=1).to_numpy()\n",
    "y=df['benign_0__mal_1'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=minmax.transform(x_train)\n",
    "X_test=minmax.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "early_stop=EarlyStopping(monitor='val_loss',mode='min',patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/anup/deep learning'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory='logs\\fit'\n",
    "\n",
    "board=TensorBoard(log_dir=log_directory,histogram_freq=1,\n",
    "                 write_graph=True,\n",
    "                 write_images=True,\n",
    "                 update_freq='epoch',\n",
    "                 embeddings_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.7094 - val_loss: 0.6836\n",
      "Epoch 2/600\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.6984 - val_loss: 0.6753\n",
      "Epoch 3/600\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.6880 - val_loss: 0.6723\n",
      "Epoch 4/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6762 - val_loss: 0.6686\n",
      "Epoch 5/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6681 - val_loss: 0.6621\n",
      "Epoch 6/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6584 - val_loss: 0.6574\n",
      "Epoch 7/600\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.6526 - val_loss: 0.6529\n",
      "Epoch 8/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6496 - val_loss: 0.6424\n",
      "Epoch 9/600\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.6311 - val_loss: 0.6233\n",
      "Epoch 10/600\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6158 - val_loss: 0.5934\n",
      "Epoch 11/600\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.5938 - val_loss: 0.5636\n",
      "Epoch 12/600\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5808 - val_loss: 0.5220\n",
      "Epoch 13/600\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5411 - val_loss: 0.4844\n",
      "Epoch 14/600\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5154 - val_loss: 0.4286\n",
      "Epoch 15/600\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4883 - val_loss: 0.3812\n",
      "Epoch 16/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.4490 - val_loss: 0.3276\n",
      "Epoch 17/600\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4226 - val_loss: 0.2843\n",
      "Epoch 18/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.3646 - val_loss: 0.2475\n",
      "Epoch 19/600\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.3848 - val_loss: 0.2272\n",
      "Epoch 20/600\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3305 - val_loss: 0.2058\n",
      "Epoch 21/600\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.3303 - val_loss: 0.1855\n",
      "Epoch 22/600\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3032 - val_loss: 0.1686\n",
      "Epoch 23/600\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3000 - val_loss: 0.1569\n",
      "Epoch 24/600\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2865 - val_loss: 0.1411\n",
      "Epoch 25/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2774 - val_loss: 0.1328\n",
      "Epoch 26/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2671 - val_loss: 0.1268\n",
      "Epoch 27/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2184 - val_loss: 0.1151\n",
      "Epoch 28/600\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.2542 - val_loss: 0.1023\n",
      "Epoch 29/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2459 - val_loss: 0.0944\n",
      "Epoch 30/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2255 - val_loss: 0.0937\n",
      "Epoch 31/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.2494 - val_loss: 0.0835\n",
      "Epoch 32/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2095 - val_loss: 0.0802\n",
      "Epoch 33/600\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2094 - val_loss: 0.0802\n",
      "Epoch 34/600\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.2120 - val_loss: 0.0793\n",
      "Epoch 35/600\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1727 - val_loss: 0.0686\n",
      "Epoch 36/600\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1859 - val_loss: 0.0657\n",
      "Epoch 37/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1812 - val_loss: 0.0745\n",
      "Epoch 38/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1649 - val_loss: 0.0668\n",
      "Epoch 39/600\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1849 - val_loss: 0.0778\n",
      "Epoch 40/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1890 - val_loss: 0.0598\n",
      "Epoch 41/600\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1792 - val_loss: 0.0611\n",
      "Epoch 42/600\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1813 - val_loss: 0.0597\n",
      "Epoch 43/600\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1610 - val_loss: 0.0621\n",
      "Epoch 44/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1980 - val_loss: 0.0775\n",
      "Epoch 45/600\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1473 - val_loss: 0.0568\n",
      "Epoch 46/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1954 - val_loss: 0.0549\n",
      "Epoch 47/600\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1704 - val_loss: 0.0560\n",
      "Epoch 48/600\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1759 - val_loss: 0.0516\n",
      "Epoch 49/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1456 - val_loss: 0.0490\n",
      "Epoch 50/600\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1548 - val_loss: 0.0560\n",
      "Epoch 51/600\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1540 - val_loss: 0.0529\n",
      "Epoch 52/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1301 - val_loss: 0.0536\n",
      "Epoch 53/600\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1452 - val_loss: 0.0536\n",
      "Epoch 54/600\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1194 - val_loss: 0.0685\n",
      "Epoch 55/600\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1308 - val_loss: 0.0580\n",
      "Epoch 56/600\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1463 - val_loss: 0.0444\n",
      "Epoch 57/600\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1355 - val_loss: 0.0445\n",
      "Epoch 58/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1441 - val_loss: 0.0556\n",
      "Epoch 59/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1284 - val_loss: 0.0578\n",
      "Epoch 60/600\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1224 - val_loss: 0.0483\n",
      "Epoch 61/600\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1229 - val_loss: 0.0425\n",
      "Epoch 62/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1145 - val_loss: 0.0455\n",
      "Epoch 63/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1295 - val_loss: 0.0503\n",
      "Epoch 64/600\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1284 - val_loss: 0.0486\n",
      "Epoch 65/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0987 - val_loss: 0.0454\n",
      "Epoch 66/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1200 - val_loss: 0.0437\n",
      "Epoch 67/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1145 - val_loss: 0.0477\n",
      "Epoch 68/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1176 - val_loss: 0.0521\n",
      "Epoch 69/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1259 - val_loss: 0.0478\n",
      "Epoch 70/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1274 - val_loss: 0.0525\n",
      "Epoch 71/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1117 - val_loss: 0.0547\n",
      "Epoch 72/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1227 - val_loss: 0.0524\n",
      "Epoch 73/600\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1055 - val_loss: 0.0494\n",
      "Epoch 74/600\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1043 - val_loss: 0.0591\n",
      "Epoch 75/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0978 - val_loss: 0.0531\n",
      "Epoch 76/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1160 - val_loss: 0.0529\n",
      "Epoch 77/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0852 - val_loss: 0.0474\n",
      "Epoch 78/600\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1253 - val_loss: 0.0467\n",
      "Epoch 79/600\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1253 - val_loss: 0.0646\n",
      "Epoch 80/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1012 - val_loss: 0.0533\n",
      "Epoch 81/600\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0914 - val_loss: 0.0659\n",
      "Epoch 82/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0973 - val_loss: 0.0504\n",
      "Epoch 83/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1006 - val_loss: 0.0495\n",
      "Epoch 84/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1285 - val_loss: 0.0500\n",
      "Epoch 85/600\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1004 - val_loss: 0.0421\n",
      "Epoch 86/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1165 - val_loss: 0.0399\n",
      "Epoch 87/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1025 - val_loss: 0.0463\n",
      "Epoch 88/600\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0865 - val_loss: 0.0427\n",
      "Epoch 89/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0933 - val_loss: 0.0502\n",
      "Epoch 90/600\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1037 - val_loss: 0.0513\n",
      "Epoch 91/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1097 - val_loss: 0.0498\n",
      "Epoch 92/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0771 - val_loss: 0.0568\n",
      "Epoch 93/600\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0784 - val_loss: 0.0546\n",
      "Epoch 94/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1194 - val_loss: 0.0509\n",
      "Epoch 95/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1045 - val_loss: 0.0544\n",
      "Epoch 96/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0871 - val_loss: 0.0487\n",
      "Epoch 97/600\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0706 - val_loss: 0.0554\n",
      "Epoch 98/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0922 - val_loss: 0.0540\n",
      "Epoch 99/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0903 - val_loss: 0.0822\n",
      "Epoch 100/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1056 - val_loss: 0.0517\n",
      "Epoch 101/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0923 - val_loss: 0.0508\n",
      "Epoch 102/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0927 - val_loss: 0.0527\n",
      "Epoch 103/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0917 - val_loss: 0.0587\n",
      "Epoch 104/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1026 - val_loss: 0.0565\n",
      "Epoch 105/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0831 - val_loss: 0.0527\n",
      "Epoch 106/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0689 - val_loss: 0.0499\n",
      "Epoch 107/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0952 - val_loss: 0.0543\n",
      "Epoch 108/600\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1219 - val_loss: 0.0595\n",
      "Epoch 109/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1022 - val_loss: 0.0553\n",
      "Epoch 110/600\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0945 - val_loss: 0.0540\n",
      "Epoch 111/600\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0837 - val_loss: 0.0564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4e8c2f2a90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=600,validation_data=(X_test,y_test),callbacks=[early_stop,board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4e5c6965e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-3b247d3863c0>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        47\n",
      "           1       0.99      0.99      0.99        67\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save('cancer_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancer_scaler.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(minmax,'cancer_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                   0.07871        1.0950         0.9053            8.589   \n",
       "1                   0.05667        0.5435         0.7339            3.398   \n",
       "2                   0.05999        0.7456         0.7869            4.585   \n",
       "3                   0.09744        0.4956         1.1560            3.445   \n",
       "4                   0.05883        0.7572         0.7813            5.438   \n",
       "..                      ...           ...            ...              ...   \n",
       "564                 0.05623        1.1760         1.2560            7.673   \n",
       "565                 0.05533        0.7655         2.4630            5.203   \n",
       "566                 0.05648        0.4564         1.0750            3.425   \n",
       "567                 0.07016        0.7260         1.5950            5.772   \n",
       "568                 0.05884        0.3857         1.4280            2.548   \n",
       "\n",
       "     area error  smoothness error  compactness error  concavity error  \\\n",
       "0        153.40          0.006399            0.04904          0.05373   \n",
       "1         74.08          0.005225            0.01308          0.01860   \n",
       "2         94.03          0.006150            0.04006          0.03832   \n",
       "3         27.23          0.009110            0.07458          0.05661   \n",
       "4         94.44          0.011490            0.02461          0.05688   \n",
       "..          ...               ...                ...              ...   \n",
       "564      158.70          0.010300            0.02891          0.05198   \n",
       "565       99.04          0.005769            0.02423          0.03950   \n",
       "566       48.55          0.005903            0.03731          0.04730   \n",
       "567       86.22          0.006522            0.06158          0.07117   \n",
       "568       19.15          0.007189            0.00466          0.00000   \n",
       "\n",
       "     concave points error  symmetry error  fractal dimension error  \\\n",
       "0                 0.01587         0.03003                 0.006193   \n",
       "1                 0.01340         0.01389                 0.003532   \n",
       "2                 0.02058         0.02250                 0.004571   \n",
       "3                 0.01867         0.05963                 0.009208   \n",
       "4                 0.01885         0.01756                 0.005115   \n",
       "..                    ...             ...                      ...   \n",
       "564               0.02454         0.01114                 0.004239   \n",
       "565               0.01678         0.01898                 0.002498   \n",
       "566               0.01557         0.01318                 0.003892   \n",
       "567               0.01664         0.02324                 0.006185   \n",
       "568               0.00000         0.02676                 0.002783   \n",
       "\n",
       "     worst radius  worst texture  worst perimeter  worst area  \\\n",
       "0          25.380          17.33           184.60      2019.0   \n",
       "1          24.990          23.41           158.80      1956.0   \n",
       "2          23.570          25.53           152.50      1709.0   \n",
       "3          14.910          26.50            98.87       567.7   \n",
       "4          22.540          16.67           152.20      1575.0   \n",
       "..            ...            ...              ...         ...   \n",
       "564        25.450          26.40           166.10      2027.0   \n",
       "565        23.690          38.25           155.00      1731.0   \n",
       "566        18.980          34.12           126.70      1124.0   \n",
       "567        25.740          39.42           184.60      1821.0   \n",
       "568         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \\\n",
       "0                  0.2654          0.4601                  0.11890   \n",
       "1                  0.1860          0.2750                  0.08902   \n",
       "2                  0.2430          0.3613                  0.08758   \n",
       "3                  0.2575          0.6638                  0.17300   \n",
       "4                  0.1625          0.2364                  0.07678   \n",
       "..                    ...             ...                      ...   \n",
       "564                0.2216          0.2060                  0.07115   \n",
       "565                0.1628          0.2572                  0.06637   \n",
       "566                0.1418          0.2218                  0.07820   \n",
       "567                0.2650          0.4087                  0.12400   \n",
       "568                0.0000          0.2871                  0.07039   \n",
       "\n",
       "     benign_0__mal_1  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "..               ...  \n",
       "564                0  \n",
       "565                0  \n",
       "566                0  \n",
       "567                0  \n",
       "568                1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_columns',None)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data=df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data=pd.DataFrame.to_json(cancer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"mean radius\":{\"0\":17.99},\"mean texture\":{\"0\":10.38},\"mean perimeter\":{\"0\":122.8},\"mean area\":{\"0\":1001.0},\"mean smoothness\":{\"0\":0.1184},\"mean compactness\":{\"0\":0.2776},\"mean concavity\":{\"0\":0.3001},\"mean concave points\":{\"0\":0.1471},\"mean symmetry\":{\"0\":0.2419},\"mean fractal dimension\":{\"0\":0.07871},\"radius error\":{\"0\":1.095},\"texture error\":{\"0\":0.9053},\"perimeter error\":{\"0\":8.589},\"area error\":{\"0\":153.4},\"smoothness error\":{\"0\":0.006399},\"compactness error\":{\"0\":0.04904},\"concavity error\":{\"0\":0.05373},\"concave points error\":{\"0\":0.01587},\"symmetry error\":{\"0\":0.03003},\"fractal dimension error\":{\"0\":0.006193},\"worst radius\":{\"0\":25.38},\"worst texture\":{\"0\":17.33},\"worst perimeter\":{\"0\":184.6},\"worst area\":{\"0\":2019.0},\"worst smoothness\":{\"0\":0.1622},\"worst compactness\":{\"0\":0.6656},\"worst concavity\":{\"0\":0.7119},\"worst concave points\":{\"0\":0.2654},\"worst symmetry\":{\"0\":0.4601},\"worst fractal dimension\":{\"0\":0.1189},\"benign_0__mal_1\":{\"0\":0}}'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_func(model,scaler,cancer_data):\n",
    "    mean_radius=cancer_data['mean radius']\n",
    "    mean_texture=cancer_data['mean texture']\n",
    "    mean perimeter=ca['mean perimeter']\n",
    "    mean_area=mean area[',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
       "       'benign_0__mal_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
